{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bz2\n",
    "import xml.sax\n",
    "import mwparserfromhell\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from time import time\n",
    "from itertools import chain\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as Threadpool\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\marku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations = set(['.', ',', ';', ':', '?', '!', '#', '\\\\', '/', '\"', '\\'', '\\'\\'', '´´', '´', '``', '`', '(', ')'])\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filters = punctuations.union(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content handler for the XML parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiXMLHandler(xml.sax.handler.ContentHandler):\n",
    "    \"\"\"Content handler for Wiki XML data using SAX\"\"\"\n",
    "    def __init__(self):\n",
    "        xml.sax.handler.ContentHandler.__init__(self)\n",
    "        self._buffer = None\n",
    "        self._values = {}\n",
    "        self._current_tag = None\n",
    "        self._previous_tag = None\n",
    "        self._pages = []\n",
    "        self._skip_page = False\n",
    "        \n",
    "        \n",
    "    def characters(self, content):\n",
    "        \"\"\"Characters between opening and closing tags\"\"\"\n",
    "        if self._current_tag:\n",
    "            self._buffer.append(content)\n",
    "            \n",
    "            \n",
    "    def startElement(self, name, attrs):\n",
    "        \"\"\"Opening tag of element\"\"\"\n",
    "        if name in ('id', 'title', 'text'):\n",
    "            self._previous_tag = self._current_tag\n",
    "            self._current_tag = name\n",
    "            self._buffer = []\n",
    "            \n",
    "        \n",
    "    def endElement(self, name):\n",
    "        \"\"\"Closing tag of element\"\"\"\n",
    "        if name == self._current_tag:\n",
    "            if name == 'text':\n",
    "                if self._redirect():\n",
    "                    self._skip_page = True\n",
    "                    pass\n",
    "                else:\n",
    "                    self._skip_page = False\n",
    "                self._process_page()\n",
    "            elif name == 'id' and self._previous_tag == 'id':\n",
    "                pass\n",
    "            else:\n",
    "                self._values[name] = ' '.join(self._buffer)\n",
    "        if name == 'page':\n",
    "            if not self._skip_page:\n",
    "                self._pages.append((self._values['id'],\n",
    "                                    self._values['title'],\n",
    "                                    self._values['text'],\n",
    "                                    self._values['wikilinks']))\n",
    "                self._page_count = len(self._pages)\n",
    "    \n",
    "    \n",
    "    def _redirect(self):\n",
    "        wiki = mwparserfromhell.parse(self._buffer)\n",
    "        text = wiki.strip_code().split()\n",
    "        if len(text) == 0:\n",
    "            return False\n",
    "        return text[0] == 'REDIRECT'\n",
    "    \n",
    "    \n",
    "    def _process_page(self):\n",
    "        content = mwparserfromhell.parse(self._buffer)\n",
    "        content = content.strip_code().strip()\n",
    "        content = mwparserfromhell.parse(content)\n",
    "        text = content.strip_code().strip()\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = filter(lambda word: word not in filters, words)\n",
    "        text = [word for word in filtered_words]\n",
    "        self._values['text'] = text\n",
    "        self._values['wikilinks'] = [x.title.strip_code() for x in content.filter_wikilinks()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56,\n",
       " 'D:/DAT500-Project-Wiki/data/enwiki-20190220-pages-articles-multistream9.xml-p1791081p2336422.bz2')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_folder = 'D:/DAT500-Project-Wiki/data/'\n",
    "partitions = [data_folder + file for file in os.listdir(data_folder) if 'xml-p']\n",
    "len(partitions), partitions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pages(data_path, save=True):\n",
    "    \"\"\"Finds and cleans all pages from a compressed wikipedia XML file\"\"\"\n",
    "    start = time()\n",
    "    # Object for handling xml\n",
    "    handler = WikiXMLHandler()\n",
    "\n",
    "    # Parsing object\n",
    "    parser = xml.sax.make_parser()\n",
    "    parser.setContentHandler(handler)\n",
    "\n",
    "    # Iteratively process file\n",
    "    i = 0\n",
    "    for line in bz2.BZ2File(data_path, 'r'):\n",
    "        try:\n",
    "            parser.feed(line)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        i += 1\n",
    "        if i > 1e+4: break\n",
    "\n",
    "    if save:\n",
    "        temp = []\n",
    "        for i, page in enumerate(handler._pages):\n",
    "            bemp.append([])\n",
    "            for j, item in enumerate(page):\n",
    "                if j == 2:\n",
    "                    b[i].append(j+1+len(item))\n",
    "                    b[i].extend(item)\n",
    "                elif j == 3:\n",
    "                    b[i].extend(item)\n",
    "                else:\n",
    "                    b[i].append(item)\n",
    "\n",
    "        csv = pd.DataFrame(temp)\n",
    "        csv.to_csv('test.csv', index=False, header=False)\n",
    "    \n",
    "    end = time()\n",
    "    print(f'\\n{data_path} preprocessed in {round(end-start)} seconds')\n",
    "    print(f'{handler._page_count} pages found in {data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "# Create a pool of workers to execute processes\n",
    "pool = Pool(processes = 4)\n",
    "\n",
    "# Map (service, task), applies function to each partition \n",
    "results = pool.map(preprocess_pages, partitions)\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "end = time()\n",
    "print(f'\\nWhole dump preprocessed in {round(end-start)} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_dump = 'data/enwiki-20190220-pages-articles-multistream1.xml-p10p30302.bz2'\n",
    "# wiki_dump = 'C:/data/enwiki-20190220-pages-articles-multistream1.xml-p10p30302.bz2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searched through 10 pages\n",
      "\n",
      "In 4 seconds\n"
     ]
    }
   ],
   "source": [
    "# Object for handling xml\n",
    "handler = WikiXMLHandler()\n",
    "# Parsing object\n",
    "parser = xml.sax.make_parser()\n",
    "parser.setContentHandler(handler)\n",
    "start = time()\n",
    "# Parse the entire file\n",
    "i = 0\n",
    "for line in bz2.BZ2File(wiki_dump):\n",
    "    try:\n",
    "        parser.feed(line)\n",
    "    except StopIteration:\n",
    "        break\n",
    "    i += 1\n",
    "    if i > 1e+4: break\n",
    "end = time()\n",
    "\n",
    "print(f'\\nSearched through {handler._page_count} pages')\n",
    "print(f'\\nIn {round(end-start)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = handler._pages[8:10]\n",
    "# print(type(a), len(a))\n",
    "# type(a[0]), type(a[1]), type(a[2]), type(a[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u0144' in position 8776: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-7f8d2dacab51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsvFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mcsvFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u0144' in position 8776: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "len(a[1][2])\n",
    "\n",
    "b = []\n",
    "for i, p in enumerate(a):\n",
    "    b.append([])\n",
    "    for j, s in enumerate(p):\n",
    "        if j == 2:\n",
    "            b[i].append(j+1+len(s))\n",
    "            b[i].extend(s)\n",
    "        elif j == 3:\n",
    "            b[i].extend(s)\n",
    "        else:\n",
    "            b[i].append(s)\n",
    "\n",
    "csvData = [['Person', 'Age', 'test'], ['Peter', '22', 'fdsafa', 'sdad'], ['Jasmine', '21'], ['Sam', '24']]\n",
    "            \n",
    "with open('test.csv', 'w') as csvFile:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerows(b)\n",
    "\n",
    "csvFile.close()\n",
    "\n",
    "\n",
    "# c = pd.DataFrame(b)\n",
    "# c.to_csv('test.csv', index=False, header=False)\n",
    "# d = pd.read_csv('test.csv', header=None)\n",
    "# d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0][3:b[2]]\n",
    "b[0][b[2]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for page in handler._pages:\n",
    "    temp.append({\n",
    "        'id': page[0],\n",
    "        'title': page[1],\n",
    "        'text': [page[2]],\n",
    "        'wikilinks': [page[3]],\n",
    "        'extlinks': [page[4]]\n",
    "    })\n",
    "csv = pd.DataFrame(temp,\n",
    "                   columns=['id', 'title', 'text', 'wikilinks', 'extlinks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>wikilinks</th>\n",
       "      <th>extlinks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>Anarchism</td>\n",
       "      <td>['Anarchism', 'anti-authoritarian', 'political...</td>\n",
       "      <td>['File:WilliamGodwin.jpg', 'File:Bakunin.png',...</td>\n",
       "      <td>['http://www.britannica.com/eb/article-9117285...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>Autism</td>\n",
       "      <td>['Autism', 'developmental', 'disorder', 'chara...</td>\n",
       "      <td>['John Wiley &amp; Sons', 'File:Single Chromosome ...</td>\n",
       "      <td>['https://www.nimh.nih.gov/health/topics/autis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>Albedo</td>\n",
       "      <td>['thumb|upright=1.3|The', 'percentage', 'diffu...</td>\n",
       "      <td>['File:water reflectivity.jpg']</td>\n",
       "      <td>['http://web.cse.ohio-state.edu/~parent.1/clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290</td>\n",
       "      <td>A</td>\n",
       "      <td>['A', 'named', 'plural', 'As', 'A', \"'s\", \"'s\"...</td>\n",
       "      <td>['File:Cretan-1.jpg', 'Aleph', 'File:Cretan-1....</td>\n",
       "      <td>['https://books.google.com/books?id=n2QWAAAAYA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>303</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>['Alabama', 'state', 'southeastern', 'region',...</td>\n",
       "      <td>['Natural Bridge, Alabama', 'AT&amp;T Inc.', 'AT&amp;T...</td>\n",
       "      <td>['http://www.oed.com/view/Entry/248152?redirec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>305</td>\n",
       "      <td>Achilles</td>\n",
       "      <td>['thumb|300px|Ancient', 'Greek', 'polychromati...</td>\n",
       "      <td>['File:The Education of Achilles 1862 Delacroi...</td>\n",
       "      <td>['http://epigraphy.packhum.org/inscriptions/se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>307</td>\n",
       "      <td>Abraham Lincoln</td>\n",
       "      <td>['Abraham', 'Lincoln', 'February', '12', '1809...</td>\n",
       "      <td>['Sarah Bush Lincoln', 'William Wallace Lincol...</td>\n",
       "      <td>['https://quod.lib.umich.edu/j/jala/2629860.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>308</td>\n",
       "      <td>Aristotle</td>\n",
       "      <td>['Aristotle', 'Aristotélēs', '384–322', 'BC', ...</td>\n",
       "      <td>['State of matter', 'File:Scyliorhinus retifer...</td>\n",
       "      <td>['https://books.google.com/?id=ZB-rVxPvtPEC&amp;pg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>309</td>\n",
       "      <td>An American in Paris</td>\n",
       "      <td>['Themes', 'An', 'American', 'Paris', 'An', 'A...</td>\n",
       "      <td>['University of Michigan School of Music, Thea...</td>\n",
       "      <td>['http://www.kennedy-center.org/calendar/?fuse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>316</td>\n",
       "      <td>Academy Award for Best Production Design</td>\n",
       "      <td>['The', 'Academy', 'Award', 'Best', 'Productio...</td>\n",
       "      <td>['Pride and Prejudice (2005 film)']</td>\n",
       "      <td>['http://awardsdatabase.oscars.org/', 'https:/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                     title  \\\n",
       "0   12                                 Anarchism   \n",
       "1   25                                    Autism   \n",
       "2   39                                    Albedo   \n",
       "3  290                                         A   \n",
       "4  303                                   Alabama   \n",
       "5  305                                  Achilles   \n",
       "6  307                           Abraham Lincoln   \n",
       "7  308                                 Aristotle   \n",
       "8  309                      An American in Paris   \n",
       "9  316  Academy Award for Best Production Design   \n",
       "\n",
       "                                                text  \\\n",
       "0  ['Anarchism', 'anti-authoritarian', 'political...   \n",
       "1  ['Autism', 'developmental', 'disorder', 'chara...   \n",
       "2  ['thumb|upright=1.3|The', 'percentage', 'diffu...   \n",
       "3  ['A', 'named', 'plural', 'As', 'A', \"'s\", \"'s\"...   \n",
       "4  ['Alabama', 'state', 'southeastern', 'region',...   \n",
       "5  ['thumb|300px|Ancient', 'Greek', 'polychromati...   \n",
       "6  ['Abraham', 'Lincoln', 'February', '12', '1809...   \n",
       "7  ['Aristotle', 'Aristotélēs', '384–322', 'BC', ...   \n",
       "8  ['Themes', 'An', 'American', 'Paris', 'An', 'A...   \n",
       "9  ['The', 'Academy', 'Award', 'Best', 'Productio...   \n",
       "\n",
       "                                           wikilinks  \\\n",
       "0  ['File:WilliamGodwin.jpg', 'File:Bakunin.png',...   \n",
       "1  ['John Wiley & Sons', 'File:Single Chromosome ...   \n",
       "2                    ['File:water reflectivity.jpg']   \n",
       "3  ['File:Cretan-1.jpg', 'Aleph', 'File:Cretan-1....   \n",
       "4  ['Natural Bridge, Alabama', 'AT&T Inc.', 'AT&T...   \n",
       "5  ['File:The Education of Achilles 1862 Delacroi...   \n",
       "6  ['Sarah Bush Lincoln', 'William Wallace Lincol...   \n",
       "7  ['State of matter', 'File:Scyliorhinus retifer...   \n",
       "8  ['University of Michigan School of Music, Thea...   \n",
       "9                ['Pride and Prejudice (2005 film)']   \n",
       "\n",
       "                                            extlinks  \n",
       "0  ['http://www.britannica.com/eb/article-9117285...  \n",
       "1  ['https://www.nimh.nih.gov/health/topics/autis...  \n",
       "2  ['http://web.cse.ohio-state.edu/~parent.1/clas...  \n",
       "3  ['https://books.google.com/books?id=n2QWAAAAYA...  \n",
       "4  ['http://www.oed.com/view/Entry/248152?redirec...  \n",
       "5  ['http://epigraphy.packhum.org/inscriptions/se...  \n",
       "6  ['https://quod.lib.umich.edu/j/jala/2629860.00...  \n",
       "7  ['https://books.google.com/?id=ZB-rVxPvtPEC&pg...  \n",
       "8  ['http://www.kennedy-center.org/calendar/?fuse...  \n",
       "9  ['http://awardsdatabase.oscars.org/', 'https:/...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.to_csv('test.csv', sep='\\t', index=False)\n",
    "d = pd.read_csv('test.csv', delimiter='\\t', \n",
    "                converters={'text': lambda x: x.strip('[]').split(', '),\n",
    "                            'wikilinks': lambda x: x.strip('[]').split(', '),\n",
    "                            'extlinks': lambda x: x.strip('[]').split(', ')})\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = d.loc[0, 'text'][0]\n",
    "# c.loc[0, 'text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anarchism'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.strip('\\'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# d.loc[0, 'extlinks'] = [word.strip('\\'') for word in d.loc[0, 'extlinks']]\n",
    "# d.loc[0, 'extlinks']\n",
    "\n",
    "type([word.strip('\\'') for word in d.loc[0, 'extlinks']])\n",
    "type(d.loc[0, 'extlinks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for line in bz2.BZ2File(wiki_dump):\n",
    "    print(line)\n",
    "    i += 1\n",
    "    if i > 2e+2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test01 = open('clean-data/test01.csv', 'r')\n",
    "i = 0\n",
    "for line in test01:\n",
    "    print(line)\n",
    "    if i > 10: break \n",
    "    else: i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309,An American in Paris,1278,Themes,An,American,Paris,An,American,Paris,jazz-influenced,orchestral,piece,American,composer,George,Gershwin,written,1928,It,inspired,time,Gershwin,spent,Paris,evokes,sights,energy,French,capital,1920s,Gershwin,composed,An,American,Paris,commission,conductor,Walter,Damrosch,He,scored,piece,standard,instruments,symphony,orchestra,plus,celesta,saxophones,automobile,horns,He,brought,back,Parisian,taxi,horns,New,York,premiere,composition,took,place,December,13,1928,Carnegie,Hall,Damrosch,conducting,New,York,Philharmonic.ALAN,GILBERT,AND,THE,NEW,YORK,PHILHARMONIC,MAKOTO,OZONE,To,Perform,GERSHWIN,â€™,S,RHAPSODY,IN,BLUE,One-Night-Only,Concert,All-American,Program,Also,To,Include,BERNSTEIN,â€™,Candide,Overture,Symphonic,Dances,West,Side,Story,GERSHWIN,'s,An,American,Paris,April,22,2014,nyphil.org,Accessed,June,20,2017,He,completed,orchestration,November,18,less,four,weeks,work,'s,premiere,He,collaborated,original,program,notes,critic,composer,Deems,Taylor,Background,Gershwin,attracted,Maurice,Ravel,'s,unusual,chords,Gershwin,went,first,trip,Paris,1926,ready,study,Ravel,After,initial,student,audition,Ravel,turned,sharing,musical,theories,Ravel,said,could,teach,saying,Why,second-rate,Ravel,first-rate,Gershwin,While,studies,cut,short,1926,trip,resulted,piece,entitled,Very,Parisienne,initial,version,An,American,Paris,written,'thank,note,Gershwin,'s,hosts,Robert,Mabel,Shirmer,Gershwin,called,rhapsodic,ballet,written,freely,much,modern,idiom,prior,works,Gershwin,strongly,encouraged,Ravel,come,United,States,tour,To,end,upon,return,New,York,Gershwin,joined,efforts,Ravel,'s,friend,Robert,Schmitz,pianist,Ravel,met,war,urge,Ravel,tour,U.S.,Schmitz,head,Pro,Musica,promoting,Franco-American,musical,relations,able,offer,Ravel,$,\"10,000\",fee,tour,enticement,Gershwin,knew,would,important,Ravel,Gershwin,greeted,Ravel,New,York,March,1928,party,held,Ravel,'s,birthday,Ã‰va,Gauthier,Ravel,'s,tour,reignited,Gershwin,'s,desire,return,Paris,brother,Ira,meeting,Ravel,Ravel,'s,high,praise,Gershwin,introductory,letter,Nadia,Boulanger,caused,Gershwin,seriously,consider,taking,much,time,study,abroad,Paris,Yet,playing,told,could,teach,Nadia,Boulanger,gave,Gershwin,basically,advice,gave,accomplished,master,students,What,could,I,give,n't,already,got,This,set,Gershwin,back,real,intent,abroad,complete,new,work,based,Paris,perhaps,second,rhapsody,piano,orchestra,follow,Rhapsody,Blue,Paris,time,hosted,many,expatriate,writers,among,Ezra,Pound,W.,B.,Yeats,Ernest,Hemingway,artist,Pablo,Picasso.LSRI,Archives,Oral,Interview,Anita,Loos,Mary,Anita,Loos,October,1979,letters,Ravel,'s,telegram,Gershwin,Composition,Gershwin,based,An,American,Paris,melodic,fragment,called,Very,Parisienne,written,1926,first,visit,Paris,gift,hosts,Robert,Mabel,Schirmer,He,described,piece,rhapsodic,ballet,written,freely,modern,previous,works,Gershwin,explained,Musical,America,My,purpose,portray,impressions,American,visitor,Paris,strolls,city,listens,various,street,noises,absorbs,French,atmosphere,The,piece,structured,five,sections,culminate,loose,ABA,format,Gershwin,'s,first,A,episode,introduces,two,main,walking,themes,Allegretto,grazioso,develops,third,theme,Subito,con,brio,The,style,A,section,written,typical,French,style,composers,Claude,Debussy,Les,Six,This,A,section,featured,duple,meter,singsong,rhythms,diatonic,melodies,sounds,oboe,English,horn,taxi,horns,The,B,section,'s,Andante,con,ritmo,deciso,introduces,American,Blues,spasms,homesickness,The,Allegro,follows,continues,express,homesickness,faster,twelve-bar,blues,In,B,section,Gershwin,uses,common,time,syncopated,rhythms,bluesy,melodies,sounds,trumpet,saxophone,snare,drum,Moderato,con,grazia,last,A,section,returns,themes,set,A,After,recapitulating,walking,themes,Gershwin,overlays,slow,blues,theme,section,B,final,Grandioso,Instrumentation,An,American,Paris,scored,3,flutes,3rd,doubling,piccolo,2,oboes,English,horn,2,clarinets,B-flat,bass,clarinet,B-flat,2,bassoons,4,horns,F,3,trumpets,B-flat,3,trombones,tuba,timpani,snare,drum,bass,drum,triangle,wood,block,cymbals,low,high,tom-toms,xylophone,glockenspiel,celesta,4,taxi,horns,labeled,A,B,C,D,circles,around,alto,saxophone/soprano,saxophone,tenor,saxophone/soprano,saxophone/alto,saxophone,baritone,saxophone/soprano,saxophone/alto,saxophone,strings,Although,modern,audiences,heard,taxi,horns,using,notes,A,B,C,D,recently,come,light,Gershwin,'s,intention,used,notes,A4,B4,D5,A4,It,likely,labeling,taxi,horns,A,B,C,D,circles,may,referring,use,four,different,horns,notes,played,The,revised,edition,F.,Campbell-Watson,calls,three,saxophones,alto,tenor,baritone,In,arrangement,soprano,alto,doublings,rewritten,avoid,changing,instruments,In,2000,Gershwin,specialist,Jack,Gibbons,made,restoration,original,orchestration,An,American,Paris,working,directly,Gershwin,'s,original,manuscript,including,restoration,Gershwin,'s,soprano,saxophone,parts,removed,F.,Campbell-Watson,'s,revision,Gibbons,restored,orchestration,An,American,Paris,performed,London,'s,Queen,Elizabeth,Hall,July,9,2000,City,Oxford,Orchestra,conducted,Levon,Parikian,William,Daly,arranged,score,piano,solo,published,New,World,Music,1929,Response,Gershwin,particularly,like,Walter,Damrosch,'s,interpretation,world,premiere,An,American,Paris,He,stated,Damrosch,'s,sluggish,dragging,tempo,caused,walk,hall,matinee,performance,work,The,audience,according,Edward,Cushing,responded,demonstration,enthusiasm,impressively,genuine,contrast,conventional,applause,new,music,good,bad,ordinarily,arouses,Critics,believed,An,American,Paris,better,crafted,lukewarm,Concerto,F.,Some,think,belonged,program,classical,composers,CÃ©sar,Franck,Richard,Wagner,Guillaume,Lekeu,premiere,Gershwin,responded,critics,It,'s,Beethoven,Symphony,know,...,It,'s,humorous,piece,nothing,solemn,It,'s,intended,draw,tears,If,pleases,symphony,audiences,light,jolly,piece,series,impressions,musically,expressed,succeeds,Preservation,status,On,September,22,2013,announced,musicological,critical,edition,full,orchestral,score,eventually,released,The,Gershwin,family,working,conjunction,Library,Congress,University,Michigan,working,make,scores,available,public,represent,Gershwin,'s,true,intent,It,unknown,critical,score,include,four,minutes,material,Gershwin,later,deleted,work,restatement,blues,theme,faster,12,bar,blues,section,score,document,changes,orchestration,Gershwin,'s,composition,process,The,score,An,American,Paris,currently,scheduled,issued,first,series,scores,released,The,entire,project,may,take,30,40,years,complete,An,American,Paris,early,volume,series,Two,urtext,editions,work,published,German,publisher,B-Note,Music,2015,The,changes,made,Campbell-Watson,withdrawn,editions,In,extended,urtext,120,bars,music,re-integrated,Conductor,Walter,Damrosch,cut,shortly,first,performance,Recordings,thumb|First,recording,An,American,Paris,frequently,recorded,The,first,recording,made,RCA,Victor,1929,Nathaniel,Shilkret,conducting,RCA,Victor,Symphony,Orchestra,drawn,members,Philadelphia,Orchestra,Gershwin,hand,supervise,recording,however,Shilkret,reported,charge,eventually,asked,composer,leave,recording,studio,Then,little,later,Shilkret,discovered,one,play,brief,celesta,solo,slow,section,hastily,asked,Gershwin,might,play,solo,Gershwin,said,could,briefly,participated,actual,recording,This,recording,believed,use,taxi,horns,way,Gershwin,intended,using,notes,A,flat,B,flat,higher,C,lower,D.,The,radio,broadcast,September,8,1937,Hollywood,Bowl,George,Gershwin,Memorial,Concert,An,American,Paris,also,conducted,Shilkret,second,program,recorded,released,1998,two-CD,set,Arthur,Fiedler,Boston,Pops,Orchestra,recorded,work,RCA,Victor,including,one,first,stereo,recordings,music,In,1945,Arturo,Toscanini,conducting,NBC,Symphony,Orchestra,recorded,piece,RCA,Victor,one,commercial,recordings,Toscanini,made,music,American,composer,The,Seattle,Symphony,also,recorded,version,1990,Gershwin,'s,original,score,made,numerous,edits,resulting,score,hear,today,Harry,James,released,version,blues,section,1953,album,One,Night,Stand,recorded,live,Aragon,Ballroom,Chicago,Columbia,GL,522,CL,522,Use,film,In,1951,Metro-Goldwyn-Mayer,released,musical,film,An,American,Paris,featuring,Gene,Kelly,Leslie,Caron,Winning,1951,Best,Picture,Oscar,numerous,awards,film,directed,Vincente,Minnelli,featured,many,tunes,Gershwin,concluded,extensive,elaborate,dance,sequence,built,around,An,American,Paris,symphonic,poem,arranged,film,Johnny,Green,costing,$,\"500,000.The\",Eddie,Mannix,Ledger,Los,Angeles,Margaret,Herrick,Library,Center,Motion,Picture,Study,References,Further,reading,Rimler,Walter,George,Gershwin,â€“,An,Intimate,Portrait,Urbana,University,Illinois,Press,2009,29â€“33,Pollack,Howard,George,Gershwin,â€“,His,Life,Work,Berkeley,University,California,Press,2006,431â€“42,External,links,1944,recording,New,York,Philharmonic,conducted,Artur,RodziÅ„ski,New,York,Philharmonic,Leonard,Bernstein,1959,Category,Compositions,George,Gershwin,Category,Symphonic,poems,Category,Grammy,Hall,Fame,Award,recipients,Category:1928,compositions,Category,Music,Paris,Category,Music,commissioned,New,York,Philharmonic,\"University of Michigan School of Music, Theatre & Dance\",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'charmap' codec can't decode byte 0x8d in position 2355: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-ed8d2d6040f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest02\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest02\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'charmap' codec can't decode byte 0x8d in position 2355: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "test02 = open('test.csv', 'r')\n",
    "i = 0\n",
    "for line in test02:\n",
    "    print(line)\n",
    "    if i > 10: break \n",
    "    else: i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
