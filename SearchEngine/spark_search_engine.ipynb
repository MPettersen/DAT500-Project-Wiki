{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark implementation of search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "from operator import add\n",
    "import pyspark\n",
    "import os\n",
    "import glob\n",
    "from time import time\n",
    "from pyspark.sql import SQLContext, Row\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPageRank(line):\n",
    "    pair = line.split(',')\n",
    "    if len(pair) > 2:\n",
    "        return ','.join(pair[:-1])[2:], float(pair[-1].strip()[:-1])\n",
    "    else:\n",
    "        return pair[0][2:-1], float(pair[1].strip()[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDF(line):\n",
    "    tf_idf = line.split(',')\n",
    "    if len(tf_idf) == 3:\n",
    "        return tf_idf[0][2:-1], (tf_idf[1].strip()[2:-1], float(tf_idf[2][2:-1].strip()[:-2]))\n",
    "    else:\n",
    "        return ','.join(tf_idf[:-2])[2:-1], (tf_idf[-2].strip()[2:-1], float(tf_idf[-1][2:-1].strip()[:-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procRDD(rdd, cache=True, part=True, hashp=True, npart=16):\n",
    "    \"\"\"\n",
    "    Helper to handle caching/partioning\n",
    "    \n",
    "    Function taken from:\n",
    "    https://stackoverflow.com/questions/31659404/spark-iteration-time-increasing-exponentially-when-using-join\n",
    "    \n",
    "    :param rdd: pyspark RDD\n",
    "    :param cache: boolean (default=True)\n",
    "    :param part: boolean (default=True)\n",
    "    :param hashp: boolean (default=True)\n",
    "    :param npart: number of partitions (default=12 suggested to be 2*(number of cores))\n",
    "    :return: rdd or rdd.cache()\n",
    "    \"\"\"\n",
    "    rdd = rdd if not part else rdd.repartition(npart)\n",
    "    rdd = rdd if not hashp else rdd.partitionBy(npart)\n",
    "    return rdd if not cache else rdd.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Spark Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark.SparkContext.setSystemProperty('spark.executor.memory', '7g')\n",
    "pyspark.SparkContext.setSystemProperty('spark.driver.cores', '2')\n",
    "pyspark.SparkContext.setSystemProperty('spark.driver.memory', '7g')\n",
    "# pyspark.SparkContext.setSystemProperty('spark.cleaner.ttl', '600')\n",
    "sc = pyspark.SparkContext(appName='search engine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_ranks = sc.textFile('file:///mnt/wiktorskit-danielb-ns0000k/home/notebook/group04/PR/page_ranks_nowiki_final/part*')\n",
    "tf_idf = sc.textFile('file:///mnt/wiktorskit-danielb-ns0000k/home/notebook/group04/TF-IDF/tf_idf_nowiki_final/part*')\n",
    "nowiki = sc.textFile('file:///mnt/wiktorskit-danielb-ns0000k/home/notebook/group04/clean_data/nowiki*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = (nowiki\n",
    "         .filter(lambda line: len(line.strip()) > 0 and\n",
    "                 not (line.strip().split('\\t')[1].find('File:') == 0) and\n",
    "                 not (line.strip().split('\\t')[1].find('Wikipedia:') == 0))\n",
    "         .map(lambda line: (line.strip().split('\\t')[1],\n",
    "                            line.strip().split('\\t')[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Akershus', '2'),\n",
       " ('Brus med ananassmak', '4'),\n",
       " ('Adjø solidaritet', '5'),\n",
       " ('Atonal musikk', '6'),\n",
       " ('Arne Dybfest', '8')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_ranks = pages_ranks.map(lambda line: getPageRank(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "679871"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_ranks.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Knole House', 2.714370680994686e-07),\n",
       " ('Kapitel', 2.2063036596032346e-07),\n",
       " ('Vorspiel', 2.637562177457272e-07),\n",
       " ('Nyhetsbyrå', 3.6482482045256115e-07),\n",
       " ('Rostrevor', 2.7067263659980717e-07)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_ranks.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR = (pages\n",
    "      .join(page_ranks, 16)\n",
    "      .map(lambda page: Row(id=page[1][0], title=page[0], rank=page[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF = tf_idf.map(lambda line: getTFIDF(line))\n",
    "grouped = (TF_IDF.groupByKey()\n",
    "           .mapValues(list)\n",
    "           .map(lambda word: Row(id=word[0], list=word[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.saveAsTextFile('/mnt/wiktorskit-danielb-ns0000k/home/notebook/group04/Search Engine/TF_IDF_grouped_01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaPR = sqlContext.createDataFrame(PR)\n",
    "schemaPR.registerTempTable('PR')\n",
    "sqlContext.cacheTable('PR')\n",
    "schemaTF_IDF = sqlContext.createDataFrame(grouped)\n",
    "schemaTF_IDF.registerTempTable('TF_IDF')\n",
    "sqlContext.cacheTable('TF_IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Row(title='Kina', rank=0.0001928447378994561)], 'Kina')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Kina'\n",
    "# query = query.lower()\n",
    "title_search = sqlContext.sql(\"SELECT title, rank FROM PR WHERE title='{}'\".format(query)).collect()\n",
    "title_search, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['dette', 'er', 'en', 'test'], ['test'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'dette er en test'\n",
    "b = 'test'\n",
    "a.split(), b.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    start = time()\n",
    "    search_res = []\n",
    "    title_search = sqlContext.sql(\"SELECT title, rank FROM PR WHERE title='{}'\".format(query)).collect()\n",
    "    if len(title_search) > 0:\n",
    "        search_res.append((title_search[0]['title'], np.inf))\n",
    "    for word in query.split():\n",
    "        results = sqlContext.sql(\"SELECT list from TF_IDF WHERE id='{}'\".format(word)).collect()\n",
    "        docs = {}\n",
    "        for result in results:\n",
    "            for row in result:\n",
    "                for item in row:\n",
    "                    if item[0] not in docs:\n",
    "                        docs[item[0]] = dict()\n",
    "                        docs[item[0]]['TF_IDF'] = item[1]\n",
    "                        res = sqlContext.sql('SELECT title, rank FROM PR WHERE id={}'.format(item[0])).collect()\n",
    "                        if len(res) > 0:\n",
    "                            docs[item[0]]['title'] = res[0]['title']\n",
    "                            docs[item[0]]['rank'] = res[0]['rank']\n",
    "                        else:\n",
    "                            docs[item[0]]['title'] = None\n",
    "                            docs[item[0]]['rank'] = 0\n",
    "                    else:\n",
    "                        docs[item[0]]['TF_IDF'] += item[1]\n",
    "        for _, doc in docs.items():\n",
    "            search_res.append((doc['title'], doc['TF_IDF']*doc['rank']))\n",
    "    search_res.sort(key=lambda tup: tup[1], reverse=True)\n",
    "    end = time()\n",
    "    print('Found', len(docs), 'matches in', round(end-start), 'seconds')\n",
    "    return search_res[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1294 matches in 326 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Chihuahua', 5.881837827315853e-07),\n",
       " ('Store hund', 2.7192508283634427e-07),\n",
       " ('Den lille hund', 2.650067042731334e-07),\n",
       " ('Kategori:Store hund', 2.3006890281200452e-07),\n",
       " ('Kategori:Den lille hund', 1.9951853785354413e-07),\n",
       " ('Hofteleddsdysplasi', 1.745383031708187e-07),\n",
       " ('Vesle hund', 1.5356277661287343e-07),\n",
       " ('Akita', 1.450065076720903e-07),\n",
       " ('Den lille hunden', 1.3820649895158621e-07),\n",
       " ('Kina', 1.3799534316859684e-07)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('hund')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 matches in 8 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Akita', inf),\n",
       " ('Japan', 9.911614979482169e-07),\n",
       " ('Akita (Akita)', 3.6962904468494163e-07),\n",
       " ('Akita', 3.5409990935597244e-07),\n",
       " ('Akita (prefektur)', 3.4223551796330036e-07),\n",
       " ('Akita (hund)', 2.309801101196431e-07),\n",
       " ('Kategori:Personer fra prefekturet Akita', 2.2171133441900993e-07),\n",
       " ('Omono', 2.007245202645245e-07),\n",
       " ('Blaublitz Akita', 1.7180549303047049e-07),\n",
       " ('Kazuno', 8.330484878096268e-08)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('Akita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53 matches in 9 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Blaublitz Akita', inf),\n",
       " ('Japan', 9.911614979482169e-07),\n",
       " ('Akita (Akita)', 3.6962904468494163e-07),\n",
       " ('Akita', 3.5409990935597244e-07),\n",
       " ('Akita (prefektur)', 3.4223551796330036e-07),\n",
       " ('Akita (hund)', 2.309801101196431e-07),\n",
       " ('Kategori:Personer fra prefekturet Akita', 2.2171133441900993e-07),\n",
       " ('Omono', 2.007245202645245e-07),\n",
       " ('Blaublitz Akita', 1.7180549303047049e-07),\n",
       " ('Blaublitz Akita', 1.156632738281266e-07)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('Blaublitz Akita')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1294 matches in 351 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Vesle hund', inf),\n",
       " ('Chihuahua', 5.881837827315853e-07),\n",
       " ('Middelhavet', 3.6759090491781353e-07),\n",
       " ('Store hund', 2.7192508283634427e-07),\n",
       " ('Den lille hund', 2.650067042731334e-07),\n",
       " ('Kategori:Store hund', 2.3006890281200452e-07),\n",
       " ('Kategori:Den lille hund', 1.9951853785354413e-07),\n",
       " ('Blefjell', 1.9786135287993907e-07),\n",
       " ('Hofteleddsdysplasi', 1.745383031708187e-07),\n",
       " ('Vesle hund', 1.5356277661287343e-07)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('Vesle hund')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search('Den lille hund')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
